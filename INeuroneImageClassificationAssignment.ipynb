{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INeuroneImageClassificationAssignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNxegskPB-67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "c419317c-b9ee-4fef-a134-e8807a8e4b66"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 133872 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.18-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.18-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.18-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PANbp5MzCMDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6fc19227-12af-4d3c-d27f-38185d5b1594"
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SX-U0X2F6kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io \n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from skimage import img_as_ubyte\n",
        "import os\n",
        "from skimage.util import random_noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syf87FLaDZV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://towardsdatascience.com/image-augmentation-using-python-numpy-opencv-and-skimage-ef027e9898da\n",
        "\n",
        "# Lets define functions for each operation\n",
        "# def anticlockwise_rotation(image):\n",
        "#     angle= random.randint(0,180)\n",
        "#     return rotate(image, angle)\n",
        "\n",
        "# def clockwise_rotation(image):\n",
        "#     angle= random.randint(0,180)\n",
        "#     return rotate(image, -angle)\n",
        "\n",
        "# def h_flip(image):\n",
        "#     return  np.fliplr(image)\n",
        "\n",
        "# # def v_flip(image):\n",
        "# #     return np.flipud(image)\n",
        "\n",
        "\n",
        "# # def add_noise(image):\n",
        "# #     return random_noise(image)\n",
        "\n",
        "# def blur_image(image):\n",
        "#     return cv2.GaussianBlur(image, (9,9),0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YarXC5D0E2LH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transformations = {'horizontal flip': h_flip, \n",
        "#                    'blurring image':blur_image\n",
        "#                  }                #use dictionary to store names of functions \n",
        "\n",
        "# images_path=\"/content/drive/ML/INeuroneImageClassification/Animesh\" #path to original images\n",
        "# augmented_path=\"/content/drive/ML/INeuroneImageClassification/Animesh_Aug\" # path to store aumented images\n",
        "# images=[] # to store paths of images from folder\n",
        "\n",
        "# for im in os.listdir(images_path):  # read image name from folder and append its path into \"images\" array     \n",
        "#     images.append(os.path.join(images_path,im))\n",
        "\n",
        "# images_to_generate=22  #you can change this value according to your requirement\n",
        "# i=1                        # variable to iterate till images_to_generate\n",
        "\n",
        "# while i<=images_to_generate:    \n",
        "#     image=random.choice(images)\n",
        "#     original_image = io.imread(image)\n",
        "#     transformed_image=None\n",
        "# #     print(i)\n",
        "#     n = 0       #variable to iterate till number of transformation to apply\n",
        "#     transformation_count = random.randint(1, len(transformations)) #choose random number of transformation to apply on the image\n",
        "#     #print(original_image)\n",
        "#     while n <= transformation_count:\n",
        "#         key = random.choice(list(transformations)) #randomly choosing method to call\n",
        "#         transformed_image = transformations[key](original_image)\n",
        "#         n = n + 1\n",
        "        \n",
        "#     new_image_path= \"%s/augmented_image_%s.jpg\" %(augmented_path, i)\n",
        "#     transformed_image = img_as_ubyte(transformed_image)  #Convert an image to unsigned byte format, with values in [0, 255].\n",
        "#     transformed_image=cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB) #convert image to RGB before saving it\n",
        "#     cv2.imwrite(new_image_path, transformed_image) # save transformed image to path\n",
        "#     i =i+1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr1fkGyeFfeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 64, 64\n",
        "\n",
        "train_data_dir = '/content/drive/ML/INeuroneImageClassification/'\n",
        "validation_data_dir = '/content/drive/ML/INeuroneImageClassification/'\n",
        "nb_train_samples = 2000\n",
        "nb_validation_samples = 800\n",
        "epochs = 5\n",
        "batch_size = 256\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTAUM0bKspuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd2qJR6ns3is",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "41dc631c-9412-47ff-fd04-8d24963e8929"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 35 images belonging to 3 classes.\n",
            "Found 35 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsQlLyd_tYcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "6a69c2b3-84ce-41ef-eded-d3f76337a03c"
      },
      "source": [
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=2000 // batch_size,\n",
        "        epochs=5,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=800 // batch_size)\n",
        "model.save_weights('imageclassification.h5')  # alw"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "7/7 [==============================] - 56s 8s/step - loss: 1.0308 - acc: 0.5061 - val_loss: 0.7266 - val_acc: 0.6857\n",
            "Epoch 2/5\n",
            "7/7 [==============================] - 33s 5s/step - loss: 0.6441 - acc: 0.7592 - val_loss: 0.3152 - val_acc: 0.9143\n",
            "Epoch 3/5\n",
            "7/7 [==============================] - 33s 5s/step - loss: 0.3527 - acc: 0.8694 - val_loss: 0.2671 - val_acc: 0.8857\n",
            "Epoch 4/5\n",
            "7/7 [==============================] - 33s 5s/step - loss: 0.2906 - acc: 0.8980 - val_loss: 0.1115 - val_acc: 0.9429\n",
            "Epoch 5/5\n",
            "7/7 [==============================] - 32s 5s/step - loss: 0.1844 - acc: 0.9347 - val_loss: 0.0816 - val_acc: 0.9429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHNfAcLyDbFN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c52fe8c4-bbb0-47f9-ee54-57c7d2cbbf19"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import load_img\n",
        "test_image = image.load_img(r\"/content/drive/ML/my_image.png\", target_size = (64, 64))\n",
        "#test_image = image.load_img(r\"/content/drive/ML/INeuroneImageClassification/Animesh/WhatsApp Image 2020-03-21 at 16.42.51 (1).jpeg\", target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)\n",
        "\n",
        "\n",
        "\n",
        "print(result)\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'Abhisek'\n",
        "    print(prediction)\n",
        "elif result[0][1] == 1:\n",
        "    prediction = 'Animesh'\n",
        "    print(prediction)\n",
        "else:\n",
        "     print(\"Biswa\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]]\n",
            "Abhisek\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h4ZjugZt6vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}